<!-- doc/src/sgml/parallel.sgml -->

 <chapter id="parallel-query">
  <title>병렬 쿼리</title>

  <indexterm zone="parallel-query">
   <primary>병렬 쿼리</primary>
  </indexterm>

  <para>
   <productname>PostgreSQL</productname>은 쿼리를 빠르게 처리하기 위해 여러
   CPU를 활용하는 실행 계획을 사용할 수 있다.  이 기능은 병렬 쿼리라고
   알려져 있다.  많은 쿼리는 병렬 처리의 이점을 누리기 어려운 이유는
   현재 구현의 제한이나 직렬 쿼리 계획보다 더 빠른 실행 계획이 없기
   때문이다.  그러나 병렬 쿼리의 속도향상에 종종 매우 중요하다.  병렬
   처리 시, 2배 혹은 4배 그 이상 빠르게 실행할 수 있다.  대량의 데이터
   중 몇몇 행만 반환할 경우 가장 큰 효과가 있다. 
  </para>

 <sect1 id="how-parallel-query-works">
  <title>병렬 쿼리 작동 원리</title>

   <para>
    옵티마이저가 특정 쿼리의 빠른 실행을 위해 병렬 처리를 할 때,
    아래와 같이 <firstterm>Gather</firstterm> 또는
    <firstterm>Gather Merge</firstterm>를 포함하여
    실행계획을 세운다:

<screen>
EXPLAIN SELECT * FROM pgbench_accounts WHERE filler LIKE '%x%';
                                     QUERY PLAN                                      
-------------------------------------------------------------------------------------
 Gather  (cost=1000.00..217018.43 rows=1 width=97)
   Workers Planned: 2
   ->  Parallel Seq Scan on pgbench_accounts  (cost=0.00..216018.33 rows=1 width=97)
         Filter: (filler ~~ '%x%'::text)
(4 rows)
</screen>
   </para>

   <para>
    위 실행 계획 경우, <literal>Gather</literal> 또는
    <literal>Gather Merge</literal>노드는 병렬로 실행되는
    계획에 정확히 하나의 하위 계획을 갖는다. <literal>Gather</literal> 노드가
    실행 계획 트리의 맨 위에 있는 경우 모든 쿼리는 병렬로 실행된다.
    If the <literal>Gather</literal> or <literal>Gather Merge</literal> node is
    at the very top of the plan tree, then the entire query will execute in
    parallel.  If it is somewhere else in the plan tree, then only the portion
    of the plan below it will run in parallel.  In the example above, the
    query accesses only one table, so there is only one plan node other than
    the <literal>Gather</literal> node itself; since that plan node is a child of the
    <literal>Gather</literal> node, it will run in parallel.
   </para>

   <para>
    <link linkend="using-explain">Using EXPLAIN</link>, you can see the number of
    workers chosen by the planner.  When the <literal>Gather</literal> node is reached
    during query execution, the process which is implementing the user's
    session will request a number of <link linkend="bgworker">background
    worker processes</link> equal to the number
    of workers chosen by the planner.  The number of background workers that
    the planner will consider using is limited to at most
    <xref linkend="guc-max-parallel-workers-per-gather"/>.  The total number
    of background workers that can exist at any one time is limited by both
    <xref linkend="guc-max-worker-processes"/> and
    <xref linkend="guc-max-parallel-workers"/>.  Therefore, it is possible for a
    parallel query to run with fewer workers than planned, or even with
    no workers at all.  The optimal plan may depend on the number of workers
    that are available, so this can result in poor query performance.  If this
    occurrence is frequent, consider increasing
    <varname>max_worker_processes</varname> and <varname>max_parallel_workers</varname>
    so that more workers can be run simultaneously or alternatively reducing
    <varname>max_parallel_workers_per_gather</varname> so that the planner
    requests fewer workers.
   </para>

   <para>
    Every background worker process which is successfully started for a given
    parallel query will execute the parallel portion of the plan.  The leader
    will also execute that portion of the plan, but it has an additional
    responsibility: it must also read all of the tuples generated by the
    workers.  When the parallel portion of the plan generates only a small
    number of tuples, the leader will often behave very much like an additional
    worker, speeding up query execution.  Conversely, when the parallel portion
    of the plan generates a large number of tuples, the leader may be almost
    entirely occupied with reading the tuples generated by the workers and
    performing any further processing steps which are required by plan nodes
    above the level of the <literal>Gather</literal> node or
    <literal>Gather Merge</literal> node.  In such cases, the leader will
    do very little of the work of executing the parallel portion of the plan.
   </para>

   <para>
    When the node at the top of the parallel portion of the plan is
    <literal>Gather Merge</literal> rather than <literal>Gather</literal>, it indicates that
    each process executing the parallel portion of the plan is producing
    tuples in sorted order, and that the leader is performing an
    order-preserving merge.  In contrast, <literal>Gather</literal> reads tuples
    from the workers in whatever order is convenient, destroying any sort
    order that may have existed.
   </para>
 </sect1>

 <sect1 id="when-can-parallel-query-be-used">
  <title>병렬 쿼리가 가능한 경우</title>

  <para>
    어떤 상황에서도 쿼리 플래너가 병렬 쿼리 계획을 생성하지 못하게
    하는 몇 가지 설정이 있다.  모든 병렬 쿼리 계획을 생성하려면
    아래와 같이 설정을 해야 한다.
  </para>

  <itemizedlist>
    <listitem>
      <para>
        <xref linkend="guc-max-parallel-workers-per-gather"/> 설정값은
        0보다 큰 수로 설정해야 한다.
        <varname>max_parallel_workers_per_gather</varname>에 설정한 수보다
        더 많은 작업자가 사용되는 것은 특수한 경우다. 
      </para>
    </listitem>

    <listitem>
      <para>
        <xref linkend="guc-dynamic-shared-memory-type"/> 설정이
        지정되어야 한다. 병렬 쿼리는 프로세스 협력에 데이터를 전달하기
        위하여 동적 공유 메모리가 필요하다. 
      </para>
    </listitem>
  </itemizedlist>

  <para>
    또한 데이터베이스 서버는 단일 사용자 모드로 실행되어서는 안된다.  전체
    데이터베이스 시스템이 싱글 프로세스로 실행되기 때문에 백그라운드 작업자는
    사용할 수 없다.
  </para>

  <para>
    병렬 쿼리 계획을 생성 할 수 있는 일반적인 경우에도, 플래너는 다음 중
    하나라도 해당되면 병렬 쿼리 실행 계획을 생성하지 않는다:
  </para>

  <itemizedlist>
    <listitem>
      <para> 
        쿼리가 데이터베이스의 로우를 쓰거나 락을 발생할 경우.  최상위
        레벨이나 CTE 내 수정 작업이 포함된 쿼리는 병렬 실행 계획은
        세워지지 않는다.  예외적으로
        <literal>CREATE TABLE ... AS</literal>, <literal>SELECT
        INTO</literal>, <literal>CREATE MATERIALIZED VIEW</literal> 작업에서는
        병렬 처리를 한다.
      </para>
    </listitem>

    <listitem>
      <para>
        쿼리가 실행 중에 중단될 수 있는 경우, 시스템은 (쿼리가) 부분 또는
        추가로 실행 가능할 수 있다고 생각하기 때문에 병렬 실행 계획이
        생성되지 않는다. 예를 들어,
        <link linkend="sql-declare">DECLARE CURSOR</link> 명령을 이용하여
        커서를 생성한 경우, PL/pgSQL의 
        <literal>FOR x IN 쿼리 LOOP .. END LOOP</literal> 형식과 같은
        루프는 병렬 쿼리로 절대로 실행되지 않는다.  왜냐하면 병렬 쿼리
        시스템은 병렬 쿼리가 실행 중일 때, 루프 내의 코드가 안전하게
        실행되는 지 검증할 수 없기 때문이다.
      </para>
    </listitem>

    <listitem>
      <para>
        쿼리가 <literal>PARALLEL UNSAFE</literal> 설정된 함수를 사용할
        경우.  대부분의 시스템 함수는 <literal>PARALLEL SAFE</literal>이지만
        기본값으로 사용자 정의 함수는 <literal>PARALLEL UNSAFE</literal>
        설정으로 만들어진다.
        이 옵션에 대한 설명은 <xref linkend="parallel-safety"/>에서 다룬다.
      </para>
    </listitem>

    <listitem>
      <para>
        쿼리가 이미 다른 쿼리 내부에서 병렬처리로 실행될 경우.  예를
        들어, 병렬 쿼리에 의해 호출된 함수가 SQL 쿼리 자체에 실행되면,
        쿼리는 병렬 실행 계획을 결코 사용하지 않는다.  현재 구현에서
        제한되어 있는데, 하나의 쿼리가 많은 수의 프로세스를 사용할
        수 있기 때문에 이 제한은 계속 유지될 예정이다.
      </para>
    </listitem>

    <listitem>
      <para>
        트랜잭션 격리 수준이 serializable일 경우.  아직 구현하지 못했음.
      </para>
    </listitem>
  </itemizedlist>

  <para>
    병렬 쿼리 계획이 특정 쿼리에서 생성된 경우라도 여러 상황에 따라
    병렬로 쿼리가 실행되지 않는다.  이 경우 <literal>Gather</literal> 노드가 없는
    것처럼 리더는 <literal>Gather</literal> 노드 아래에 있는 실행 계획 부분을
    전체를 자체적으로 실행한다.  이런 경우는 다음 조건 중 하나가 충족
    될 경우 발생한다.
  </para>

  <itemizedlist>
    <listitem>
      <para>
        No background workers can be obtained because of the limitation that
        the total number of background workers cannot exceed
        <xref linkend="guc-max-worker-processes"/>.
      </para>
    </listitem>

    <listitem>
      <para>
        No background workers can be obtained because of the limitation that
        the total number of background workers launched for purposes of
        parallel query cannot exceed <xref linkend="guc-max-parallel-workers"/>.
      </para>
    </listitem>

    <listitem>
      <para>
        The client sends an Execute message with a non-zero fetch count.
        See the discussion of the
        <link linkend="protocol-flow-ext-query">extended query protocol</link>.
        Since <link linkend="libpq">libpq</link> currently provides no way to
        send such a message, this can only occur when using a client that
        does not rely on libpq.  If this is a frequent
        occurrence, it may be a good idea to set
        <xref linkend="guc-max-parallel-workers-per-gather"/> to zero in
        sessions where it is likely, so as to avoid generating query plans
        that may be suboptimal when run serially.
      </para>
    </listitem>

    <listitem>
      <para>
        The transaction isolation level is serializable.  This situation
        does not normally arise, because parallel query plans are not
        generated when the transaction isolation level is serializable.
        However, it can happen if the transaction isolation level is changed to
        serializable after the plan is generated and before it is executed.
      </para>
    </listitem>
  </itemizedlist>
 </sect1>

 <sect1 id="parallel-plans">
  <title>Parallel Plans</title>

  <para>
    Because each worker executes the parallel portion of the plan to
    completion, it is not possible to simply take an ordinary query plan
    and run it using multiple workers.  Each worker would produce a full
    copy of the output result set, so the query would not run any faster
    than normal but would produce incorrect results.  Instead, the parallel
    portion of the plan must be what is known internally to the query
    optimizer as a <firstterm>partial plan</firstterm>; that is, it must be constructed
    so that each process which executes the plan will generate only a
    subset of the output rows in such a way that each required output row
    is guaranteed to be generated by exactly one of the cooperating processes.
    Generally, this means that the scan on the driving table of the query
    must be a parallel-aware scan.
  </para>

 <sect2 id="parallel-scans">
  <title>Parallel Scans</title>

  <para>
    The following types of parallel-aware table scans are currently supported.

  <itemizedlist>
    <listitem>
      <para>
        In a <emphasis>parallel sequential scan</emphasis>, the table's blocks will
        be divided among the cooperating processes.  Blocks are handed out one
        at a time, so that access to the table remains sequential.
      </para>
    </listitem>
    <listitem>
      <para>
        In a <emphasis>parallel bitmap heap scan</emphasis>, one process is chosen
        as the leader.  That process performs a scan of one or more indexes
        and builds a bitmap indicating which table blocks need to be visited.
        These blocks are then divided among the cooperating processes as in
        a parallel sequential scan.  In other words, the heap scan is performed
        in parallel, but the underlying index scan is not.
      </para>
    </listitem>
    <listitem>
      <para>
        In a <emphasis>parallel index scan</emphasis> or <emphasis>parallel index-only
        scan</emphasis>, the cooperating processes take turns reading data from the
        index.  Currently, parallel index scans are supported only for
        btree indexes.  Each process will claim a single index block and will
        scan and return all tuples referenced by that block; other process can
        at the same time be returning tuples from a different index block.
        The results of a parallel btree scan are returned in sorted order
        within each worker process.
      </para>
    </listitem>
  </itemizedlist>

    Other scan types, such as scans of non-btree indexes, may support
    parallel scans in the future.
  </para>
 </sect2>

 <sect2 id="parallel-joins">
  <title>Parallel Joins</title>

  <para>
    Just as in a non-parallel plan, the driving table may be joined to one or
    more other tables using a nested loop, hash join, or merge join.  The
    inner side of the join may be any kind of non-parallel plan that is
    otherwise supported by the planner provided that it is safe to run within
    a parallel worker.  Depending on the join type, the inner side may also be
    a parallel plan.
  </para>

  <itemizedlist>
    <listitem>
      <para>
        In a <emphasis>nested loop join</emphasis>, the inner side is always
        non-parallel.  Although it is executed in full, this is efficient if
        the inner side is an index scan, because the outer tuples and thus
        the loops that look up values in the index are divided over the
        cooperating processes.
      </para>
    </listitem>
    <listitem>
      <para>
        In a <emphasis>merge join</emphasis>, the inner side is always
        a non-parallel plan and therefore executed in full.  This may be
        inefficient, especially if a sort must be performed, because the work
        and resulting data are duplicated in every cooperating process.
      </para>
    </listitem>
    <listitem>
      <para>
        In a <emphasis>hash join</emphasis> (without the "parallel" prefix),
        the inner side is executed in full by every cooperating process
        to build identical copies of the hash table.  This may be inefficient
        if the hash table is large or the plan is expensive.  In a
        <emphasis>parallel hash join</emphasis>, the inner side is a
        <emphasis>parallel hash</emphasis> that divides the work of building
        a shared hash table over the cooperating processes.
      </para>
    </listitem>
  </itemizedlist>
 </sect2>

 <sect2 id="parallel-aggregation">
  <title>Parallel Aggregation</title>
  <para>
    <productname>PostgreSQL</productname> supports parallel aggregation by aggregating in
    two stages.  First, each process participating in the parallel portion of
    the query performs an aggregation step, producing a partial result for
    each group of which that process is aware.  This is reflected in the plan
    as a <literal>Partial Aggregate</literal> node.  Second, the partial results are
    transferred to the leader via <literal>Gather</literal> or <literal>Gather
    Merge</literal>.  Finally, the leader re-aggregates the results across all
    workers in order to produce the final result.  This is reflected in the
    plan as a <literal>Finalize Aggregate</literal> node.
  </para>
  
  <para>
    Because the <literal>Finalize Aggregate</literal> node runs on the leader
    process, queries which produce a relatively large number of groups in
    comparison to the number of input rows will appear less favorable to the
    query planner. For example, in the worst-case scenario the number of
    groups seen by the <literal>Finalize Aggregate</literal> node could be as many as
    the number of input rows which were seen by all worker processes in the
    <literal>Partial Aggregate</literal> stage. For such cases, there is clearly
    going to be no performance benefit to using parallel aggregation. The
    query planner takes this into account during the planning process and is
    unlikely to choose parallel aggregate in this scenario.
  </para>

  <para>
    Parallel aggregation is not supported in all situations.  Each aggregate
    must be <link linkend="parallel-safety">safe</link> for parallelism and must
    have a combine function.  If the aggregate has a transition state of type
    <literal>internal</literal>, it must have serialization and deserialization
    functions.  See <xref linkend="sql-createaggregate"/> for more details.
    Parallel aggregation is not supported if any aggregate function call
    contains <literal>DISTINCT</literal> or <literal>ORDER BY</literal> clause and is also
    not supported for ordered set aggregates or when  the query involves
    <literal>GROUPING SETS</literal>.  It can only be used when all joins involved in
    the query are also part of the parallel portion of the plan.
  </para>

 </sect2>

 <sect2 id="parallel-append">
  <title>Parallel Append</title>

  <para>
    Whenever <productname>PostgreSQL</productname> needs to combine rows
    from multiple sources into a single result set, it uses an
    <literal>Append</literal> or <literal>MergeAppend</literal> plan node.
    This commonly happens when implementing <literal>UNION ALL</literal> or
    when scanning a partitioned table.  Such nodes can be used in parallel
    plans just as they can in any other plan.  However, in a parallel plan,
    the planner may instead use a <literal>Parallel Append</literal> node.
  </para>

  <para>
    When an <literal>Append</literal> node is used in a parallel plan, each
    process will execute the child plans in the order in which they appear,
    so that all participating processes cooperate to execute the first child
    plan until it is complete and then move to the second plan at around the
    same time.  When a <literal>Parallel Append</literal> is used instead, the
    executor will instead spread out the participating processes as evenly as
    possible across its child plans, so that multiple child plans are executed
    simultaneously.  This avoids contention, and also avoids paying the startup
    cost of a child plan in those processes that never execute it.
  </para>

  <para>
    Also, unlike a regular <literal>Append</literal> node, which can only have
    partial children when used within a parallel plan, a <literal>Parallel
    Append</literal> node can have both partial and non-partial child plans.
    Non-partial children will be scanned by only a single process, since
    scanning them more than once would produce duplicate results.  Plans that
    involve appending multiple results sets can therefore achieve
    coarse-grained parallelism even when efficient partial plans are not
    available.  For example, consider a query against a partitioned table
    which can be only be implemented efficiently by using an index that does
    not support parallel scans.  The planner might choose a <literal>Parallel
    Append</literal> of regular <literal>Index Scan</literal> plans; each
    individual index scan would have to be executed to completion by a single
    process, but different scans could be performed at the same time by
    different processes.
  </para>

  <para>
    <xref linkend="guc-enable-parallel-append" /> can be used to disable
    this feature.
  </para>
 </sect2>

 <sect2 id="parallel-plan-tips">
  <title>Parallel Plan Tips</title>

  <para>
    If a query that is expected to do so does not produce a parallel plan,
    you can try reducing <xref linkend="guc-parallel-setup-cost"/> or
    <xref linkend="guc-parallel-tuple-cost"/>.  Of course, this plan may turn
    out to be slower than the serial plan which the planner preferred, but
    this will not always be the case.  If you don't get a parallel
    plan even with very small values of these settings (e.g. after setting
    them both to zero), there may be some reason why the query planner is
    unable to generate a parallel plan for your query.  See
    <xref linkend="when-can-parallel-query-be-used"/> and
    <xref linkend="parallel-safety"/> for information on why this may be
    the case.
  </para>

  <para>
    When executing a parallel plan, you can use <literal>EXPLAIN (ANALYZE,
    VERBOSE)</literal> to display per-worker statistics for each plan node.
    This may be useful in determining whether the work is being evenly
    distributed between all plan nodes and more generally in understanding the
    performance characteristics of the plan.
  </para>

 </sect2>
 </sect1>

 <sect1 id="parallel-safety">
  <title>Parallel Safety</title>

  <para>
    The planner classifies operations involved in a query as either
    <firstterm>parallel safe</firstterm>, <firstterm>parallel restricted</firstterm>,
    or <firstterm>parallel unsafe</firstterm>.  A parallel safe operation is one which
    does not conflict with the use of parallel query.  A parallel restricted
    operation is one which cannot be performed in a parallel worker, but which
    can be performed in the leader while parallel query is in use.  Therefore,
    parallel restricted operations can never occur below a <literal>Gather</literal>
    or <literal>Gather Merge</literal> node, but can occur elsewhere in a plan which
    contains such a node.  A parallel unsafe operation is one which cannot
    be performed while parallel query is in use, not even in the leader.
    When a query contains anything which is parallel unsafe, parallel query
    is completely disabled for that query.
  </para>

  <para>
    The following operations are always parallel restricted.
  </para>

  <itemizedlist>
    <listitem>
      <para>
        Scans of common table expressions (CTEs).
      </para>
    </listitem>

    <listitem>
      <para>
        Scans of temporary tables.
      </para>
    </listitem>

    <listitem>
      <para>
        Scans of foreign tables, unless the foreign data wrapper has
        an <literal>IsForeignScanParallelSafe</literal> API which indicates otherwise.
      </para>
    </listitem>

    <listitem>
      <para>
        Plan nodes to which an <literal>InitPlan</literal> is attached.
      </para>
    </listitem>

    <listitem>
      <para>
        Plan nodes which reference a correlated <literal>SubPlan</literal>.
      </para>
    </listitem>
  </itemizedlist>

 <sect2 id="parallel-labeling">
  <title>Parallel Labeling for Functions and Aggregates</title>

  <para>
    The planner cannot automatically determine whether a user-defined
    function or aggregate is parallel safe, parallel restricted, or parallel
    unsafe, because this would require predicting every operation which the
    function could possibly perform.  In general, this is equivalent to the
    Halting Problem and therefore impossible.  Even for simple functions
    where it could conceivably be done, we do not try, since this would be expensive
    and error-prone.  Instead, all user-defined functions are assumed to
    be parallel unsafe unless otherwise marked.  When using
    <xref linkend="sql-createfunction"/> or
    <xref linkend="sql-alterfunction"/>, markings can be set by specifying
    <literal>PARALLEL SAFE</literal>, <literal>PARALLEL RESTRICTED</literal>, or
    <literal>PARALLEL UNSAFE</literal> as appropriate.  When using
    <xref linkend="sql-createaggregate"/>, the
    <literal>PARALLEL</literal> option can be specified with <literal>SAFE</literal>,
    <literal>RESTRICTED</literal>, or <literal>UNSAFE</literal> as the corresponding value.
  </para>

  <para>
    Functions and aggregates must be marked <literal>PARALLEL UNSAFE</literal> if
    they write to the database, access sequences, change the transaction state
    even temporarily (e.g. a PL/pgSQL function which establishes an
    <literal>EXCEPTION</literal> block to catch errors), or make persistent changes to
    settings.  Similarly, functions must be marked <literal>PARALLEL
    RESTRICTED</literal> if they access temporary tables, client connection state,
    cursors, prepared statements, or miscellaneous backend-local state which
    the system cannot synchronize across workers. For example,
    <literal>setseed</literal> and <literal>random</literal> are parallel restricted for
    this last reason.
  </para>

  <para>
    In general, if a function is labeled as being safe when it is restricted or
    unsafe, or if it is labeled as being restricted when it is in fact unsafe,
    it may throw errors or produce wrong answers when used in a parallel query.
    C-language functions could in theory exhibit totally undefined behavior if
    mislabeled, since there is no way for the system to protect itself against
    arbitrary C code, but in most likely cases the result will be no worse than
    for any other function. If in doubt, it is probably best to label functions
    as <literal>UNSAFE</literal>.
  </para>

  <para>
    If a function executed within a parallel worker acquires locks which are
    not held by the leader, for example by querying a table not referenced in
    the query, those locks will be released at worker exit, not end of
    transaction. If you write a function which does this, and this behavior
    difference is important to you, mark such functions as
    <literal>PARALLEL RESTRICTED</literal>
    to ensure that they execute only in the leader.
  </para>

  <para>
    Note that the query planner does not consider deferring the evaluation of
    parallel-restricted functions or aggregates involved in the query in
    order to obtain a superior plan.  So, for example, if a <literal>WHERE</literal>
    clause applied to a particular table is parallel restricted, the query
    planner will not consider performing a scan of that table in the parallel
    portion of a plan.  In some cases, it would be
    possible (and perhaps even efficient) to include the scan of that table in
    the parallel portion of the query and defer the evaluation of the
    <literal>WHERE</literal> clause so that it happens above the <literal>Gather</literal>
    node.  However, the planner does not do this.
  </para>

 </sect2>

 </sect1>

 </chapter>
